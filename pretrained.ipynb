{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a30d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.utils.data as utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368da16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Photo</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Photo  Male\n",
       "0       000001.jpg     0\n",
       "1       000002.jpg     0\n",
       "2       000003.jpg     1\n",
       "3       000004.jpg     0\n",
       "4       000005.jpg     0\n",
       "...            ...   ...\n",
       "202594  202595.jpg     0\n",
       "202595  202596.jpg     1\n",
       "202596  202597.jpg     1\n",
       "202597  202598.jpg     0\n",
       "202598  202599.jpg     0\n",
       "\n",
       "[202599 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"list_attr_celeba.csv\")\n",
    "\n",
    "df = df.loc[:, [\"Photo\", \"Male\"]]\n",
    "df.loc[(df[\"Male\"] == -1), \"Male\"] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6158417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"Photo\"] == \"000005.jpg\", \"Male\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22450032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(utils.Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels.loc[df[\"Photo\"] == img_path[17:], \"Male\"].values[0]\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b102904",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25),\n",
    "    transforms.CenterCrop(227),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "directory = \"img_align_celeba\"\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "file_paths = [os.path.join(directory, file_name) for file_name in file_names]\n",
    "\n",
    "celeb_data = CustomDataset(file_paths, df, transform)\n",
    "celeb_subset = torch.utils.data.Subset(celeb_data, range(5000))\n",
    "\n",
    "celeb_split_data = utils.random_split(celeb_subset, lengths=[0.7, 0.3])\n",
    "\n",
    "pre_train_dataloader = utils.DataLoader(dataset=celeb_split_data[0], batch_size=64, shuffle=True)\n",
    "pre_val_dataloader = utils.DataLoader(dataset=celeb_split_data[1], batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f574e9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       " \n",
       "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       " \n",
       "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e5f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=6, stride=6, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=384, out_features=512, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (relu5): ReLU()\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=7, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=6, stride=6)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(384, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Layers\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = self.dropout1(self.relu4(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "model = CNN(num_classes)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "084308f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.worst_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.worst_score is None:\n",
    "            self.worst_score = val_loss\n",
    "        elif val_loss < self.worst_score - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.worst_score = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99047379",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fa7d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "def train_loop(model, train_dataloader, val_dataloader, criterion, optimizer):\n",
    "    val_acc = []\n",
    "    earlyStopper = EarlyStopping()\n",
    "    print('Training...')\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'--Epoch {epoch+1}--')\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "            print(f\"Batch: {batch_idx}\")\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        train_accuracy = 100. * correct / len(train_dataloader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_dataloader:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        if earlyStopper(loss.item()):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        val_accuracy = 100. * correct / len(val_dataloader.dataset)\n",
    "        val_acc.append(val_accuracy)\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_dataloader):.4f}, Accuracy: {train_accuracy:.2f}%, Test Loss: {val_loss/len(val_dataloader):.4f}, Test Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b15ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, test_dataloader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print(f'Test Loss: {test_loss/len(test_dataloader):.4f}, Test Accuracy: {100. * correct / len(test_dataloader.dataset):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1b1a50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "--Epoch 1--\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Epoch 1, Loss: 0.6787, Accuracy: 59.66%, Test Loss: 0.7018, Test Accuracy: 54.40%\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, pre_train_dataloader, pre_val_dataloader, criterion, optimizer)\n",
    "\n",
    "torch.save(model, 'celeba_pretrained_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "709080cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = datasets.ImageFolder(root='gender', transform=transform)\n",
    "gender_split_data = utils.random_split(gender_data, lengths=[0.4, 0.3, 0.3])\n",
    "\n",
    "train_dataloader = utils.DataLoader(dataset=gender_split_data[0], batch_size=64, shuffle=True)\n",
    "val_dataloader = utils.DataLoader(dataset=gender_split_data[1], batch_size=64, shuffle=True)\n",
    "test_dataloader = utils.DataLoader(dataset=gender_split_data[2], batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "775d7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc3 = nn.Linear(model.fc3.in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a82bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "--Epoch 1--\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Epoch 1, Loss: 0.6953, Accuracy: 49.62%, Test Loss: 0.6939, Test Accuracy: 49.86%\n",
      "Test Loss: 0.6944, Test Accuracy: 49.93%\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_dataloader, val_dataloader, criterion, optimizer)\n",
    "test_loop(model, test_dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77942c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
